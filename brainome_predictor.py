#!/usr/bin/env python3
#
# This code has been produced by a free evaluation version of Brainome(tm).
# Portions of this code copyright (c) 2019-2022 by Brainome, Inc. All Rights Reserved.
# Brainome, Inc grants an exclusive (subject to our continuing rights to use and modify models),
# worldwide, non-sublicensable, and non-transferable limited license to use and modify this
# predictor produced through the input of your data:
# (i) for users accessing the service through a free evaluation account, solely for your
# own non-commercial purposes, including for the purpose of evaluating this service, and
# (ii) for users accessing the service through a paid, commercial use account, for your
# own internal  and commercial purposes.
# Please contact support@brainome.ai with any questions.
# Use of predictions results at your own risk.
#
# Output of Brainome v2.0-172-prod.
# Invocation: brainome -headerless waterbirds_mobilenet_final_layer_normalized.csv -vvv
# Total compiler execution time: 0:03:36.47. Finished on: Dec-14-2022 00:53:37.
# This source code requires Python 3.
#
"""

[01;1mPredictor:[0m                        
    Classifier Type:              Neural Network
    System Type:                  Binary classifier
    Training / Validation Split:  60% : 40%
    Accuracy:
      Best-guess accuracy:        76.79%
      Training accuracy:          99.61% (2865/2876 correct)
      Validation Accuracy:        94.78% (1819/1919 correct)
      Combined Model Accuracy:    97.68% (4684/4795 correct)


    Model Capacity (MEC):      2053    bits
    Generalization Ratio:         1.09 bits/bit
    Percent of Data Memorized:   201.90%
    Resilience to Noise:          -0.14 dB



    System Meter Runtime Duration:    7s
    Training Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   0 |  2199    10 
                   1 |     1   666 

    Validation Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   0 |  1431    42 
                   1 |    58   388 

    Combined Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   0 |  3630    52 
                   1 |    59  1054 

    Training Accuracy by Class:
                1024 |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS 
                ---- | ----- ----- ----- ----- -------- -------- -------- -------- -------- --------
                   0 |  2199     1   666    10   99.55%   99.85%   99.95%   98.52%   99.75%   99.50%
                   1 |   666    10  2199     1   99.85%   99.55%   98.52%   99.95%   99.18%   98.38%

    Validation Accuracy by Class:
                1024 |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS 
                ---- | ----- ----- ----- ----- -------- -------- -------- -------- -------- --------
                   0 |  1431    58   388    42   97.15%   87.00%   96.10%   90.23%   96.62%   93.47%
                   1 |   388    42  1431    58   87.00%   97.15%   90.23%   96.10%   88.58%   79.51%

    Combined Accuracy by Class:
                1024 |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS 
                ---- | ----- ----- ----- ----- -------- -------- -------- -------- -------- --------
                   0 |  3630    59  1054    52   98.59%   94.70%   98.40%   95.30%   98.49%   97.03%
                   1 |  1054    52  3630    59   94.70%   98.59%   95.30%   98.40%   95.00%   90.47%


"""

import argparse
import binascii
import csv
import faulthandler
import json
import math
import sys

try:
    import numpy as np  # For numpy see: http://numpy.org
except ImportError as e:
    print(
        "This predictor requires the Numpy library. Please run 'python3 -m pip install numpy'.",
        file=sys.stderr,
    )
    raise e
try:
    from scipy.sparse import coo_matrix

    report_cmat = True
except ImportError:
    print(
        "Note: If you install scipy (https://www.scipy.org) this predictor generates a confusion matrix. Try 'python3 -m pip install scipy'.",
        file=sys.stderr,
    )
    report_cmat = False

IOBUFF = 100000000
sys.setrecursionlimit(1000000)
random_filler_value = "ba8db6eb493e918dd0b9b7facc14a63caf0749d4510adbd022df4c13b8ba8f5f"
TRAINFILE = ["waterbirds_mobilenet_final_layer_normalized.csv"]
mapping = {"0": 0, "1": 1}
ignorelabels = []
ignorecolumns = []
target = "1024"
target_column = 1024
important_idxs = [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37,
    38,
    39,
    40,
    41,
    42,
    43,
    44,
    45,
    46,
    47,
    48,
    49,
    50,
    51,
    52,
    53,
    54,
    55,
    56,
    57,
    58,
    59,
    60,
    61,
    62,
    63,
    64,
    65,
    66,
    67,
    68,
    69,
    70,
    71,
    72,
    73,
    74,
    75,
    76,
    77,
    78,
    79,
    80,
    81,
    82,
    83,
    84,
    85,
    86,
    87,
    88,
    89,
    90,
    91,
    92,
    93,
    94,
    95,
    96,
    97,
    98,
    99,
    100,
    101,
    102,
    103,
    104,
    105,
    106,
    107,
    108,
    109,
    110,
    111,
    112,
    113,
    114,
    115,
    116,
    117,
    118,
    119,
    120,
    121,
    122,
    123,
    124,
    125,
    126,
    127,
    128,
    129,
    130,
    131,
    132,
    133,
    134,
    135,
    136,
    137,
    138,
    139,
    140,
    141,
    142,
    143,
    144,
    145,
    146,
    147,
    148,
    149,
    150,
    151,
    152,
    153,
    154,
    155,
    156,
    157,
    158,
    159,
    160,
    161,
    162,
    163,
    164,
    165,
    166,
    167,
    168,
    169,
    170,
    171,
    172,
    173,
    174,
    175,
    176,
    177,
    178,
    179,
    180,
    181,
    182,
    183,
    184,
    185,
    186,
    187,
    188,
    189,
    190,
    191,
    192,
    193,
    194,
    195,
    196,
    197,
    198,
    199,
    200,
    201,
    202,
    203,
    204,
    205,
    206,
    207,
    208,
    209,
    210,
    211,
    212,
    213,
    214,
    215,
    216,
    217,
    218,
    219,
    220,
    221,
    222,
    223,
    224,
    225,
    226,
    227,
    228,
    229,
    230,
    231,
    232,
    233,
    234,
    235,
    236,
    237,
    238,
    239,
    240,
    241,
    242,
    243,
    244,
    245,
    246,
    247,
    248,
    249,
    250,
    251,
    252,
    253,
    254,
    255,
    256,
    257,
    258,
    259,
    260,
    261,
    262,
    263,
    264,
    265,
    266,
    267,
    268,
    269,
    270,
    271,
    272,
    273,
    274,
    275,
    276,
    277,
    278,
    279,
    280,
    281,
    282,
    283,
    284,
    285,
    286,
    287,
    288,
    289,
    290,
    291,
    292,
    293,
    294,
    295,
    296,
    297,
    298,
    299,
    300,
    301,
    302,
    303,
    304,
    305,
    306,
    307,
    308,
    309,
    310,
    311,
    312,
    313,
    314,
    315,
    316,
    317,
    318,
    319,
    320,
    321,
    322,
    323,
    324,
    325,
    326,
    327,
    328,
    329,
    330,
    331,
    332,
    333,
    334,
    335,
    336,
    337,
    338,
    339,
    340,
    341,
    342,
    343,
    344,
    345,
    346,
    347,
    348,
    349,
    350,
    351,
    352,
    353,
    354,
    355,
    356,
    357,
    358,
    359,
    360,
    361,
    362,
    363,
    364,
    365,
    366,
    367,
    368,
    369,
    370,
    371,
    372,
    373,
    374,
    375,
    376,
    377,
    378,
    379,
    380,
    381,
    382,
    383,
    384,
    385,
    386,
    387,
    388,
    389,
    390,
    391,
    392,
    393,
    394,
    395,
    396,
    397,
    398,
    399,
    400,
    401,
    402,
    403,
    404,
    405,
    406,
    407,
    408,
    409,
    410,
    411,
    412,
    413,
    414,
    415,
    416,
    417,
    418,
    419,
    420,
    421,
    422,
    423,
    424,
    425,
    426,
    427,
    428,
    429,
    430,
    431,
    432,
    433,
    434,
    435,
    436,
    437,
    438,
    439,
    440,
    441,
    442,
    443,
    444,
    445,
    446,
    447,
    448,
    449,
    450,
    451,
    452,
    453,
    454,
    455,
    456,
    457,
    458,
    459,
    460,
    461,
    462,
    463,
    464,
    465,
    466,
    467,
    468,
    469,
    470,
    471,
    472,
    473,
    474,
    475,
    476,
    477,
    478,
    479,
    480,
    481,
    482,
    483,
    484,
    485,
    486,
    487,
    488,
    489,
    490,
    491,
    492,
    493,
    494,
    495,
    496,
    497,
    498,
    499,
    500,
    501,
    502,
    503,
    504,
    505,
    506,
    507,
    508,
    509,
    510,
    511,
    512,
    513,
    514,
    515,
    516,
    517,
    518,
    519,
    520,
    521,
    522,
    523,
    524,
    525,
    526,
    527,
    528,
    529,
    530,
    531,
    532,
    533,
    534,
    535,
    536,
    537,
    538,
    539,
    540,
    541,
    542,
    543,
    544,
    545,
    546,
    547,
    548,
    549,
    550,
    551,
    552,
    553,
    554,
    555,
    556,
    557,
    558,
    559,
    560,
    561,
    562,
    563,
    564,
    565,
    566,
    567,
    568,
    569,
    570,
    571,
    572,
    573,
    574,
    575,
    576,
    577,
    578,
    579,
    580,
    581,
    582,
    583,
    584,
    585,
    586,
    587,
    588,
    589,
    590,
    591,
    592,
    593,
    594,
    595,
    596,
    597,
    598,
    599,
    600,
    601,
    602,
    603,
    604,
    605,
    606,
    607,
    608,
    609,
    610,
    611,
    612,
    613,
    614,
    615,
    616,
    617,
    618,
    619,
    620,
    621,
    622,
    623,
    624,
    625,
    626,
    627,
    628,
    629,
    630,
    631,
    632,
    633,
    634,
    635,
    636,
    637,
    638,
    639,
    640,
    641,
    642,
    643,
    644,
    645,
    646,
    647,
    648,
    649,
    650,
    651,
    652,
    653,
    654,
    655,
    656,
    657,
    658,
    659,
    660,
    661,
    662,
    663,
    664,
    665,
    666,
    667,
    668,
    669,
    670,
    671,
    672,
    673,
    674,
    675,
    676,
    677,
    678,
    679,
    680,
    681,
    682,
    683,
    684,
    685,
    686,
    687,
    688,
    689,
    690,
    691,
    692,
    693,
    694,
    695,
    696,
    697,
    698,
    699,
    700,
    701,
    702,
    703,
    704,
    705,
    706,
    707,
    708,
    709,
    710,
    711,
    712,
    713,
    714,
    715,
    716,
    717,
    718,
    719,
    720,
    721,
    722,
    723,
    724,
    725,
    726,
    727,
    728,
    729,
    730,
    731,
    732,
    733,
    734,
    735,
    736,
    737,
    738,
    739,
    740,
    741,
    742,
    743,
    744,
    745,
    746,
    747,
    748,
    749,
    750,
    751,
    752,
    753,
    754,
    755,
    756,
    757,
    758,
    759,
    760,
    761,
    762,
    763,
    764,
    765,
    766,
    767,
    768,
    769,
    770,
    771,
    772,
    773,
    774,
    775,
    776,
    777,
    778,
    779,
    780,
    781,
    782,
    783,
    784,
    785,
    786,
    787,
    788,
    789,
    790,
    791,
    792,
    793,
    794,
    795,
    796,
    797,
    798,
    799,
    800,
    801,
    802,
    803,
    804,
    805,
    806,
    807,
    808,
    809,
    810,
    811,
    812,
    813,
    814,
    815,
    816,
    817,
    818,
    819,
    820,
    821,
    822,
    823,
    824,
    825,
    826,
    827,
    828,
    829,
    830,
    831,
    832,
    833,
    834,
    835,
    836,
    837,
    838,
    839,
    840,
    841,
    842,
    843,
    844,
    845,
    846,
    847,
    848,
    849,
    850,
    851,
    852,
    853,
    854,
    855,
    856,
    857,
    858,
    859,
    860,
    861,
    862,
    863,
    864,
    865,
    866,
    867,
    868,
    869,
    870,
    871,
    872,
    873,
    874,
    875,
    876,
    877,
    878,
    879,
    880,
    881,
    882,
    883,
    884,
    885,
    886,
    887,
    888,
    889,
    890,
    891,
    892,
    893,
    894,
    895,
    896,
    897,
    898,
    899,
    900,
    901,
    902,
    903,
    904,
    905,
    906,
    907,
    908,
    909,
    910,
    911,
    912,
    913,
    914,
    915,
    916,
    917,
    918,
    919,
    920,
    921,
    922,
    923,
    924,
    925,
    926,
    927,
    928,
    929,
    930,
    931,
    932,
    933,
    934,
    935,
    936,
    937,
    938,
    939,
    940,
    941,
    942,
    943,
    944,
    945,
    946,
    947,
    948,
    949,
    950,
    951,
    952,
    953,
    954,
    955,
    956,
    957,
    958,
    959,
    960,
    961,
    962,
    963,
    964,
    965,
    966,
    967,
    968,
    969,
    970,
    971,
    972,
    973,
    974,
    975,
    976,
    977,
    978,
    979,
    980,
    981,
    982,
    983,
    984,
    985,
    986,
    987,
    988,
    989,
    990,
    991,
    992,
    993,
    994,
    995,
    996,
    997,
    998,
    999,
    1000,
    1001,
    1002,
    1003,
    1004,
    1005,
    1006,
    1007,
    1008,
    1009,
    1010,
    1011,
    1012,
    1013,
    1014,
    1015,
    1016,
    1017,
    1018,
    1019,
    1020,
    1021,
    1022,
    1023,
]
expected_feature_cols = 1024
classifier_type = "NN"
num_attr = 1024
n_classes = 2
model_cap = 2053
w_h = np.array(
    [
        [
            -0.12808750569820404,
            -0.01278386265039444,
            0.0012412839569151402,
            -0.007224882487207651,
            -0.029116028919816017,
            -0.07519938051700592,
            -0.07543743401765823,
            -0.04417988657951355,
            -0.09073789417743683,
            -0.01970011740922928,
            -0.12793247401714325,
            -0.011619925498962402,
            -0.10989295691251755,
            0.006298491731286049,
            -0.1160026267170906,
            -0.12678523361682892,
            0.01574343629181385,
            0.007937435060739517,
            -0.10766533017158508,
            -0.0321100577712059,
            -0.06928947567939758,
            -0.020045604556798935,
            -0.08080174028873444,
            -0.09703903645277023,
            -0.08875656872987747,
            -0.11944460868835449,
            -0.07593382149934769,
            -0.09509027004241943,
            -0.03577318415045738,
            -0.010837512090802193,
            -0.00875157117843628,
            -0.11388453096151352,
            -0.07882083207368851,
            -0.12084519863128662,
            -0.06255526095628738,
            -0.11925556510686874,
            -0.014457073993980885,
            -0.011538871563971043,
            -0.10166109353303909,
            0.01730569452047348,
            -0.08829830586910248,
            -0.0045804427936673164,
            -0.07554231584072113,
            -0.027034573256969452,
            -0.11143959313631058,
            -0.016605515033006668,
            -0.028368540108203888,
            -0.004222122486680746,
            -0.11275210976600647,
            -0.06260279566049576,
            -0.04460196942090988,
            -0.107877716422081,
            -0.06574156880378723,
            -0.10307790338993073,
            -0.04474681243300438,
            -0.07297476381063461,
            -0.07032585144042969,
            -0.056470200419425964,
            -0.09485584497451782,
            -0.04599062353372574,
            -0.06551239639520645,
            -0.11045768857002258,
            -0.016597239300608635,
            -0.09481325000524521,
            -0.04979262873530388,
            -0.03838258236646652,
            -0.13096454739570618,
            -0.05230008810758591,
            -0.07882630825042725,
            -0.09174371510744095,
            -0.09171883761882782,
            -0.07380682229995728,
            -0.010718670673668385,
            -0.04532233625650406,
            -0.11208660900592804,
            -0.0715348869562149,
            -0.071672223508358,
            -0.017315711826086044,
            -0.07396087050437927,
            -0.06121065095067024,
            -0.1089397519826889,
            -0.020711170509457588,
            -0.0646284967660904,
            -0.0954868346452713,
            -0.07492266595363617,
            -0.10547109693288803,
            -0.07051219046115875,
            -0.06658726185560226,
            -0.11377494782209396,
            -0.10970554500818253,
            -0.11746403574943542,
            -0.07927395403385162,
            -0.0025438261218369007,
            -0.04028905928134918,
            -0.0032405443489551544,
            -0.051867999136447906,
            -0.07043389230966568,
            -0.09705111384391785,
            -0.11198875308036804,
            -0.10202660411596298,
            -0.02903314307332039,
            -0.051364876329898834,
            -0.044341351836919785,
            0.008738535456359386,
            -0.10068267583847046,
            -0.09142332524061203,
            0.014001693576574326,
            -0.11169032752513885,
            -0.016154270619153976,
            -0.054011788219213486,
            -0.022110870108008385,
            -0.006672425661236048,
            0.010794253088533878,
            -0.06676977127790451,
            0.018573125824332237,
            -0.11071193218231201,
            -0.08227578550577164,
            -0.016303708776831627,
            -0.0541897751390934,
            -0.10069255530834198,
            -0.00973368901759386,
            -0.03086172789335251,
            -0.09229137748479843,
            -0.09547674655914307,
            -0.11038923263549805,
            0.011031968519091606,
            -0.13045810163021088,
            0.013534728437662125,
            -0.021599240601062775,
            -0.08203799277544022,
            0.005956392269581556,
            -0.07186394184827805,
            -0.10268997400999069,
            -0.04907894879579544,
            -0.040026139467954636,
            -0.1194482073187828,
            -0.060145679861307144,
            -0.08425832539796829,
            -0.049178577959537506,
            -0.026651455089449883,
            -0.08899033069610596,
            0.004969491623342037,
            -0.07981317490339279,
            -0.04402361437678337,
            -0.03714212402701378,
            -0.06029254198074341,
            -0.12692835927009583,
            -0.08290979266166687,
            -0.07567552477121353,
            -0.05716581642627716,
            0.006098776124417782,
            -0.1005174070596695,
            -7.415196887450293e-05,
            0.006974019575864077,
            -0.04210403561592102,
            -0.0040954602882266045,
            -0.10723251849412918,
            0.00760124996304512,
            -0.11584299802780151,
            -0.07255849987268448,
            0.0088050477206707,
            -0.03546186164021492,
            -0.10431744158267975,
            -0.0655139833688736,
            0.007696850690990686,
            -0.1257385015487671,
            0.008998813107609749,
            -0.08591059595346451,
            0.019855089485645294,
            -0.09505477547645569,
            -0.0901494026184082,
            -0.09949544072151184,
            -0.008058050647377968,
            -0.07594697922468185,
            -0.11469065397977829,
            -0.033970821648836136,
            -0.03621802479028702,
            -0.12665167450904846,
            -0.05496590957045555,
            -0.12376278638839722,
            0.011279968544840813,
            0.00855100154876709,
            -0.12574131786823273,
            -0.04339613765478134,
            -0.09982820600271225,
            -0.07534028589725494,
            0.0010423532221466303,
            -0.009788325987756252,
            -0.06764589995145798,
            0.014002684503793716,
            -0.03625165671110153,
            -0.019930167123675346,
            -0.12520334124565125,
            -0.039936453104019165,
            2.7095209588878788e-05,
            -0.024895496666431427,
            -0.07221362739801407,
            -0.12028279900550842,
            -0.015359778888523579,
            -0.09260783344507217,
            -0.03162718191742897,
            -0.09904330968856812,
            -0.09904838353395462,
            -0.07005643099546432,
            -0.05074663460254669,
            -0.09821052104234695,
            0.011369072832167149,
            -0.07382316887378693,
            0.021479200571775436,
            0.0038874750025570393,
            -0.0227273590862751,
            -0.04890982434153557,
            -0.015669584274291992,
            -0.11465994268655777,
            -0.017423896118998528,
            -0.02761095017194748,
            0.008031734265387058,
            -0.07844262570142746,
            -0.037096574902534485,
            -0.05768045037984848,
            -0.06069490686058998,
            -0.06629843264818192,
            0.016053207218647003,
            -0.07424366474151611,
            -0.021732181310653687,
            -0.049800723791122437,
            -0.013608942739665508,
            -0.011712991632521152,
            -0.13022880256175995,
            -0.08387406170368195,
            -0.057008400559425354,
            -0.0361441969871521,
            -0.040917083621025085,
            -0.07383286207914352,
            -0.026311879977583885,
            -0.0030546109192073345,
            -0.08959384262561798,
            -0.026393001899123192,
            0.003531714901328087,
            -0.0894041657447815,
            -0.12394466251134872,
            -0.11361772567033768,
            -0.014325986616313457,
            0.02180382050573826,
            -0.12539638578891754,
            -0.00920618325471878,
            0.0042596058920025826,
            -0.03438453748822212,
            -0.03284735232591629,
            -0.10150996595621109,
            -0.037324439734220505,
            -0.04759518802165985,
            -0.04167856648564339,
            -0.12702448666095734,
            -0.017046749591827393,
            -0.042429715394973755,
            -0.009128137491643429,
            -0.008157513104379177,
            -0.057267140597105026,
            -0.07747570425271988,
            0.009982534684240818,
            -0.016319092363119125,
            -0.06374259293079376,
            -0.06149469316005707,
            -0.09205842763185501,
            0.019475506618618965,
            -0.12738892436027527,
            -0.06831351667642593,
            -0.011262461543083191,
            -0.05364379659295082,
            -0.07262822240591049,
            -0.039790671318769455,
            0.013043778017163277,
            -0.030600078403949738,
            -0.09475888311862946,
            -0.09016023576259613,
            -0.048182565718889236,
            -0.09377659857273102,
            -0.12381463497877121,
            -0.037924934178590775,
            -0.04572947323322296,
            -0.026216989383101463,
            -0.013349763117730618,
            0.009068833664059639,
            0.0018677635816857219,
            -0.023464426398277283,
            -0.06688991189002991,
            -0.11616726219654083,
            -0.026957452297210693,
            -0.07320448011159897,
            0.008506489917635918,
            -0.003035525791347027,
            -0.018674256280064583,
            -0.06289520114660263,
            -0.12536466121673584,
            -0.007126534357666969,
            -0.02712041325867176,
            -0.03620593622326851,
            0.017185688018798828,
            -0.06182589381933212,
            0.001905397279188037,
            -0.1085553914308548,
            -0.08547470718622208,
            -0.016355328261852264,
            -0.09887097775936127,
            -0.13075226545333862,
            -0.04634464159607887,
            -0.10495644807815552,
            -0.059084996581077576,
            0.009578786790370941,
            -0.023999014869332314,
            -0.003795935772359371,
            -0.07592024654150009,
            -0.07407617568969727,
            -0.030916374176740646,
            -0.1099700927734375,
            -0.005375192034989595,
            -0.009304516948759556,
            -0.07368829846382141,
            -0.029854431748390198,
            -0.09695234149694443,
            -0.0027645763475447893,
            -0.10288470983505249,
            -0.08476152271032333,
            -0.01859249919652939,
            -0.04467358440160751,
            -0.0777106061577797,
            -0.027668172493577003,
            -0.12625640630722046,
            -0.05196294188499451,
            0.016921391710639,
            0.021245716139674187,
            0.0038940527010709047,
            -0.11382792145013809,
            0.01841232180595398,
            -0.0803864449262619,
            0.01442668866366148,
            -0.0961187481880188,
            -0.048091426491737366,
            -0.06517836451530457,
            -0.10195822268724442,
            -0.035790082067251205,
            -0.11325003951787949,
            -0.021012386307120323,
            -0.115971140563488,
            -0.10581567138433456,
            0.01012179534882307,
            -0.11195524036884308,
            0.005886082537472248,
            -0.0425969734787941,
            -0.05260395631194115,
            -0.013756711967289448,
            -0.10593966394662857,
            -0.07949511706829071,
            -0.022718805819749832,
            -0.113749660551548,
            -0.09263481199741364,
            -0.08541673421859741,
            -0.06313719600439072,
            -0.12365832924842834,
            -0.12296627461910248,
            -0.0827062726020813,
            -0.08326391130685806,
            -0.050845593214035034,
            -0.015168695710599422,
            -0.11799361556768417,
            -0.11835994571447372,
            -0.12553080916404724,
            0.01971280388534069,
            -0.06587142497301102,
            -0.07372501492500305,
            0.0008927359012886882,
            -0.02833622321486473,
            -0.11690106987953186,
            -0.12602365016937256,
            -0.05147569999098778,
            -0.09551921486854553,
            -0.03001304715871811,
            -0.08835223317146301,
            -0.05779816210269928,
            -0.12155283242464066,
            -0.13055776059627533,
            -0.028954047709703445,
            0.008779216557741165,
            -0.064676433801651,
            -0.1285693645477295,
            -0.04538397490978241,
            -0.09431875497102737,
            0.01337167527526617,
            -0.08149874955415726,
            -0.09937629103660583,
            -0.1271897256374359,
            -0.10526639223098755,
            -0.10633683949708939,
            -0.07626709342002869,
            -0.016611279919743538,
            -0.10186130553483963,
            -0.06611651182174683,
            -0.11717232316732407,
            -0.017660770565271378,
            -0.031842395663261414,
            -0.0812792256474495,
            -0.10935503989458084,
            -0.07261687517166138,
            -0.010677204467356205,
            -0.07771211117506027,
            -0.020282307639718056,
            -0.005268118344247341,
            0.006262832786887884,
            -0.03865758702158928,
            0.015503643080592155,
            -0.02927280031144619,
            -0.08342120051383972,
            -0.04141344502568245,
            -0.047984614968299866,
            -0.12860795855522156,
            -0.0321957990527153,
            -0.09492500126361847,
            -0.02122456580400467,
            -0.08306150883436203,
            -0.084425188601017,
            -0.0192328542470932,
            -0.003010837361216545,
            -0.06284388154745102,
            -0.005684003699570894,
            -0.011246374808251858,
            -0.12273713201284409,
            -0.04827530309557915,
            -0.07266228646039963,
            -0.10370991379022598,
            -0.10247133672237396,
            -0.0902726873755455,
            -0.07008777558803558,
            0.01919218897819519,
            -0.12745828926563263,
            -0.1037609726190567,
            -0.09295175224542618,
            -0.06305542588233948,
            -0.07033532112836838,
            -0.10976780951023102,
            -0.08787089586257935,
            -0.10170901566743851,
            -0.04821736738085747,
            0.01694897934794426,
            -0.006000082474201918,
            -0.031070033088326454,
            -0.03028019703924656,
            -0.042157132178545,
            -0.048654232174158096,
            -0.1065877377986908,
            -0.07316791266202927,
            -0.0970088392496109,
            -0.08471011370420456,
            -0.08934265375137329,
            -0.0936075821518898,
            0.015450618229806423,
            -0.05988531559705734,
            -0.09085358679294586,
            -0.09999965131282806,
            -0.041660986840724945,
            -0.1089337095618248,
            0.0064019858837127686,
            0.015200309455394745,
            -0.034102242439985275,
            -0.12542517483234406,
            -0.12579865753650665,
            -0.05840231478214264,
            0.011313027702271938,
            -0.0259171761572361,
            -0.05832139030098915,
            0.01549544744193554,
            -0.01568969339132309,
            -0.12291539460420609,
            -0.05890105664730072,
            -0.11677738279104233,
            -0.0826229676604271,
            -0.07576838880777359,
            -0.12035708874464035,
            -0.0427083894610405,
            -0.11338461935520172,
            0.008542729541659355,
            -0.09246329218149185,
            0.00034047261578962207,
            -0.002326076850295067,
            0.008241468109190464,
            -0.09420721977949142,
            -0.003802743274718523,
            -0.06021174043416977,
            -0.055858492851257324,
            -0.09193067252635956,
            -0.0034217971842736006,
            -0.0018207156099379063,
            -0.03149721026420593,
            -0.11459433287382126,
            0.002702926518395543,
            -0.06750363111495972,
            -0.03777701035141945,
            -0.03709748387336731,
            -0.059324100613594055,
            -0.000202052659005858,
            -0.12038910388946533,
            -0.030087068676948547,
            -0.10412868112325668,
            -0.051332682371139526,
            0.021009569987654686,
            -0.09460272639989853,
            -0.11881659179925919,
            -0.06069384887814522,
            -0.08458729833364487,
            -0.12612952291965485,
            0.007800128310918808,
            -0.10051971673965454,
            -0.07444113492965698,
            -0.07164209336042404,
            -0.07222546637058258,
            -0.09720972180366516,
            -0.040665820240974426,
            -0.031142333522439003,
            -0.09922811388969421,
            -0.04230060055851936,
            -0.0497366227209568,
            -0.12344767153263092,
            -0.11954844743013382,
            -0.04233277589082718,
            -0.0013952513691037893,
            0.004246355965733528,
            0.006884152535349131,
            -0.12409987300634384,
            -0.008719700388610363,
            0.016813017427921295,
            0.0029910465236753225,
            0.01012973953038454,
            -0.1287539005279541,
            -0.0999167412519455,
            -0.034338515251874924,
            -0.06557702273130417,
            0.0184874776750803,
            -0.12219038605690002,
            -0.12491626292467117,
            -0.006090306211262941,
            -0.12666049599647522,
            -0.041436128318309784,
            0.002684838604182005,
            -0.0011601183796301484,
            -0.13086745142936707,
            -0.08162616938352585,
            -0.11422409117221832,
            -0.055213142186403275,
            -0.025884782895445824,
            -0.03948599472641945,
            -0.05062718316912651,
            -0.03755311667919159,
            -0.060306668281555176,
            -0.08129436522722244,
            0.017283428460359573,
            -0.1276678591966629,
            0.007703967858105898,
            0.0009360139956697822,
            -0.04709719493985176,
            -0.1254088580608368,
            -0.06730692088603973,
            -0.04653584957122803,
            -0.00688192481175065,
            -0.002295031910762191,
            -0.017781171947717667,
            0.0004542614333331585,
            -0.006134102586656809,
            -0.0982639417052269,
            -0.07541895657777786,
            -0.12767955660820007,
            -0.1081414595246315,
            -0.07443302869796753,
            -0.0024902222212404013,
            -0.012301072478294373,
            -0.05834006145596504,
            -0.038244593888521194,
            -0.07632490992546082,
            -0.02736109495162964,
            -0.06906545907258987,
            -0.10700563341379166,
            0.008428514003753662,
            0.0025366542395204306,
            -0.04491454362869263,
            -0.08737234026193619,
            -0.1216677725315094,
            -0.03966069594025612,
            -0.004345306660979986,
            -0.03307756781578064,
            -0.08356437087059021,
            -0.11704836785793304,
            -0.025043727830052376,
            0.005485054571181536,
            0.009200508706271648,
            -0.046922966837882996,
            -0.11130481958389282,
            -0.015856536105275154,
            -0.09004507958889008,
            -0.0145072927698493,
            -0.017109042033553123,
            0.006172074470669031,
            0.008572517894208431,
            -0.07031837850809097,
            -0.0905841663479805,
            0.016490722075104713,
            0.019689161330461502,
            -0.009814418852329254,
            0.014956395141780376,
            0.019608093425631523,
            0.009404545649886131,
            -0.1261744201183319,
            -0.04773581773042679,
            0.003542462596669793,
            -0.09892309457063675,
            -0.06648484617471695,
            -0.11733097583055496,
            -0.07056541740894318,
            -0.0576816126704216,
            -0.021894359961152077,
            -0.0375194288790226,
            -0.09184074401855469,
            -0.04086774215102196,
            -0.0021578650921583176,
            -0.016692999750375748,
            -0.0847996324300766,
            -0.10608383268117905,
            -0.06824823468923569,
            0.009307704865932465,
            0.002092795679345727,
            0.005676748231053352,
            -0.05223381146788597,
            -0.07207166403532028,
            -0.04744797572493553,
            -0.09967724233865738,
            -0.022878792136907578,
            -0.01862163469195366,
            -0.1071491464972496,
            0.014860892668366432,
            -0.03335809335112572,
            -0.1241903230547905,
            0.0163568202406168,
            0.011307126842439175,
            -0.05833595246076584,
            -0.0723799467086792,
            -0.12715578079223633,
            0.017160259187221527,
            0.009598769247531891,
            -0.006441925652325153,
            -0.06716480851173401,
            -0.05746035650372505,
            -0.129139244556427,
            -0.09155070036649704,
            -0.05643557757139206,
            -0.06744935363531113,
            -0.11397769302129745,
            0.008399083279073238,
            -0.04369626194238663,
            -0.09670959413051605,
            0.0010655891383066773,
            -0.0584355928003788,
            -0.03098655864596367,
            -0.00800232868641615,
            -0.07432793080806732,
            -0.09361071139574051,
            -0.10766013711690903,
            -0.067816361784935,
            -0.043808676302433014,
            -0.029239723458886147,
            -0.06159462779760361,
            -0.09461560100317001,
            -0.003704814938828349,
            -0.031229667365550995,
            0.011673364788293839,
            -0.08803118020296097,
            -0.10599058866500854,
            0.005676461849361658,
            -0.019180601462721825,
            -0.02547197788953781,
            -0.09871634095907211,
            -0.03240814059972763,
            -0.001119244028814137,
            -0.06795267015695572,
            -0.12294263392686844,
            -0.09325093775987625,
            -0.026120763272047043,
            -0.08321744948625565,
            -0.12337334454059601,
            -0.03122062049806118,
            0.00012820345000363886,
            0.0029145400039851665,
            -0.09613953530788422,
            -0.04714586213231087,
            -0.04508090764284134,
            -0.06615517288446426,
            0.01789524033665657,
            -0.11303552240133286,
            0.003660899121314287,
            -0.09257814288139343,
            -0.014415419660508633,
            -0.11049530655145645,
            -0.045892249792814255,
            -0.11191403865814209,
            0.021815845742821693,
            -0.08181558549404144,
            -0.04441246762871742,
            -0.010533192194998264,
            -0.03829556331038475,
            -0.11644352972507477,
            -0.006046155467629433,
            0.017486535012722015,
            -0.06854350119829178,
            -0.03226605802774429,
            -0.11403924971818924,
            0.013993236236274242,
            -0.09033258259296417,
            -0.06238565221428871,
            -0.07265076041221619,
            -0.027093268930912018,
            -0.08132261037826538,
            0.006673245225101709,
            -0.015630291774868965,
            -0.005498018581420183,
            -0.02479409985244274,
            -0.021337702870368958,
            -0.04401589557528496,
            -0.015829728916287422,
            -0.00407752487808466,
            -0.025164928287267685,
            -0.1038614958524704,
            -0.02834320440888405,
            -0.056246671825647354,
            0.015054224990308285,
            -0.10965410619974136,
            -0.04517088457942009,
            -0.12191209942102432,
            -0.10651382058858871,
            0.020715773105621338,
            -0.06153668463230133,
            -0.09541711211204529,
            -0.08100590109825134,
            -0.04996131360530853,
            -0.051926389336586,
            -0.017754975706338882,
            -0.04430230334401131,
            0.0052053057588636875,
            -0.05672229453921318,
            -0.04480055347084999,
            0.017192546278238297,
            -0.042286477982997894,
            -0.10745961964130402,
            -0.07355375587940216,
            -0.08909052610397339,
            -0.0404072031378746,
            -0.12499786168336868,
            -0.12140882760286331,
            -0.03976321220397949,
            -0.04598434641957283,
            -0.007035822607576847,
            -0.04678455740213394,
            -0.1285736858844757,
            -0.07369525730609894,
            -0.09088672697544098,
            -0.02862945944070816,
            -0.05066821351647377,
            -0.06971099227666855,
            -0.12571656703948975,
            -0.06130989268422127,
            -0.0733107179403305,
            -0.027602653950452805,
            -0.014833602122962475,
            -0.04033541679382324,
            -0.06738053262233734,
            -0.01999499276280403,
            -0.0003318699018564075,
            -0.06597825139760971,
            0.00019733085355255753,
            -0.03298208490014076,
            -0.02282518520951271,
            -0.104962557554245,
            -0.05632792413234711,
            -0.08482035249471664,
            0.01805420033633709,
            -0.11447185277938843,
            -0.05681757628917694,
            -0.05261668562889099,
            -0.007644941098988056,
            0.010722602717578411,
            -0.04990619421005249,
            -0.021562738344073296,
            -0.12988317012786865,
            -0.04924052208662033,
            -0.0782911404967308,
            -0.039260171353816986,
            -0.021335404366254807,
            -0.11895933747291565,
            -0.015495787374675274,
            -0.08705741167068481,
            -0.05485301837325096,
            -0.0035498461220413446,
            -0.012539856135845184,
            -0.07020627707242966,
            -0.019582290202379227,
            -0.011735598556697369,
            -0.0373634397983551,
            -0.051775939762592316,
            -0.07952531427145004,
            -0.10086333751678467,
            -0.08315211534500122,
            -0.02669149450957775,
            -0.10728354007005692,
            -0.0476788654923439,
            0.0009382364805787802,
            -0.12288542836904526,
            -0.0961773693561554,
            -0.0065983193926513195,
            -0.09785931557416916,
            0.01658451557159424,
            -0.06352213025093079,
            0.0013752683298662305,
            -0.10220403969287872,
            -0.061810459941625595,
            -0.0220145545899868,
            -0.10639894008636475,
            0.0007326487102545798,
            0.00023942715779412538,
            -0.05026896670460701,
            -0.120282843708992,
            -0.025450443848967552,
            -0.08976705372333527,
            -0.10753638297319412,
            0.017811361700296402,
            -0.06732337176799774,
            -0.07297265529632568,
            -0.04722919315099716,
            -0.11195936053991318,
            -0.007246683351695538,
            -0.06150346249341965,
            0.017793789505958557,
            -0.10344506055116653,
            -0.11212830990552902,
            -0.04341994598507881,
            -0.05591591075062752,
            -0.038415879011154175,
            -0.08905371278524399,
            -0.01144898310303688,
            -0.122703418135643,
            -0.09251649677753448,
            0.014879721216857433,
            -0.12428682297468185,
            -0.09322220832109451,
            -0.05764887109398842,
            0.007119364105165005,
            -0.12566576898097992,
            -0.0202636681497097,
            -0.08505244553089142,
            -0.024851305410265923,
            0.015064949169754982,
            -0.004733515437692404,
            -0.0011029640445485711,
            -0.07450767606496811,
            0.01978561095893383,
            -0.12316419184207916,
            -0.04215918481349945,
            -0.007868833839893341,
            -0.07761720567941666,
            0.005413552280515432,
            -0.05129639804363251,
            0.009080307558178902,
            0.016252348199486732,
            -0.08433461934328079,
            -0.04088575392961502,
            -0.09994244575500488,
            -0.01955530233681202,
            -0.098595030605793,
            -0.019588220864534378,
            -0.10016457736492157,
            -0.004247897304594517,
            -0.0901687741279602,
            -0.10870973765850067,
            -0.015369431115686893,
            -0.08311626315116882,
            -0.043447867035865784,
            -0.12379109859466553,
            -0.12725819647312164,
            -0.12719662487506866,
            -0.10388987511396408,
            -0.11985588818788528,
            -0.020126119256019592,
            -0.0530959814786911,
            0.013717660680413246,
            -0.05925450846552849,
            -0.05308021977543831,
            -0.0962691530585289,
            -0.05899468809366226,
            -0.013953665271401405,
            -0.09291581064462662,
            -0.1274636834859848,
            -0.06559975445270538,
            -0.11011344939470291,
            -0.08472388237714767,
            0.012635869905352592,
            0.0148250637575984,
            0.02098388969898224,
            -0.05090320482850075,
            -0.10145798325538635,
            -0.0034277813974767923,
            -0.06978549808263779,
            -0.1159696951508522,
            -0.09017480909824371,
            -0.012895623221993446,
            -0.12683816254138947,
            -0.07767699658870697,
            -0.1087670847773552,
            0.011345581151545048,
            0.0019181625684723258,
            -0.01735207438468933,
            -0.09629970788955688,
            -0.12524352967739105,
            -0.04438738524913788,
            -0.11764024943113327,
            -0.07980678975582123,
            -0.03812916949391365,
            0.0028974227607250214,
            0.002352004172280431,
            -0.13105539977550507,
            -0.11470802128314972,
            -0.10288688540458679,
            -0.06233531981706619,
            -0.06918280571699142,
            -0.00820202473551035,
            -0.0007822238840162754,
            -0.10198164731264114,
            -0.08598779141902924,
            -0.059119369834661484,
            -0.07246171683073044,
            -0.08131300657987595,
            -0.06427432596683502,
            -0.01750849187374115,
            0.018583077937364578,
            -0.07003245502710342,
            -0.04065448045730591,
            -0.13049520552158356,
            -0.050539590418338776,
            -0.04032636433839798,
            -0.04956670477986336,
            -0.0888822078704834,
            -0.026896769180893898,
            -0.10004879534244537,
            -0.09668459743261337,
            -0.060869790613651276,
            -0.049846697598695755,
            -0.08856041729450226,
            0.006239492446184158,
            -0.01153456699103117,
            -0.0005136216641403735,
            -0.00964612141251564,
            -0.029383772984147072,
            -0.10690723359584808,
            -0.12967731058597565,
            -0.083478644490242,
            -0.019031235948204994,
            -0.0937005952000618,
            -0.05733536183834076,
            -0.09511661529541016,
            -0.05338443070650101,
            -0.10046332329511642,
            -0.09160955250263214,
            -0.02753005363047123,
            -0.12360773235559464,
            -0.0005328592960722744,
            -0.07759518176317215,
            -0.10714646428823471,
            -0.05893930792808533,
            -0.06869449466466904,
            -0.12503010034561157,
            -0.0059954579919576645,
            0.02005508914589882,
            -0.12761346995830536,
            -0.07720176130533218,
            -0.07456113398075104,
            -0.032936371862888336,
            -0.017726417630910873,
            -0.07652867585420609,
            -0.11485693603754044,
            -0.07658626139163971,
            -0.03538346663117409,
            -0.00025750830536708236,
            -0.11436426639556885,
            0.007324838545173407,
            -0.022454578429460526,
            -0.05001240223646164,
            -0.10210083425045013,
            -0.06146598607301712,
            -0.04658927395939827,
            -0.012504171580076218,
            0.008766098879277706,
            -0.09977035224437714,
            0.0006671212031506002,
            -0.12147030979394913,
            -0.0792720690369606,
            -0.06326241791248322,
            -0.05658707022666931,
            -0.059567201882600784,
            -0.05382123216986656,
            -0.041385896503925323,
            -0.05227223411202431,
            -0.11165475100278854,
            0.0002613184624351561,
            -0.04974100738763809,
            0.007630706299096346,
            -0.05881381034851074,
            0.006975398864597082,
            -0.01908736489713192,
            -0.04844451695680618,
            -0.11061624437570572,
            0.00959321390837431,
            -0.04594298079609871,
            0.004728435073047876,
            -0.1006120890378952,
            -0.027335043996572495,
            -0.05972876027226448,
            -0.010836740024387836,
            0.00642534252256155,
            -0.12307845056056976,
            -0.08648061752319336,
        ],
        [
            -0.627851128578186,
            -0.5366655588150024,
            0.06972280144691467,
            0.01150495558977127,
            0.001619534334167838,
            -0.11284022033214569,
            -0.022474927827715874,
            -0.17131420969963074,
            0.4880814254283905,
            -0.04972471669316292,
            -0.00658085523173213,
            0.33942511677742004,
            0.30073264241218567,
            -0.784099280834198,
            -0.7830145359039307,
            -0.33741575479507446,
            -0.3149947226047516,
            0.5785267353057861,
            0.08298380672931671,
            0.046217840164899826,
            0.051842231303453445,
            -0.7422634959220886,
            -0.38635435700416565,
            0.38210827112197876,
            -0.05918146297335625,
            -0.41518330574035645,
            -0.33964091539382935,
            -0.27642080187797546,
            -0.47581520676612854,
            0.4330977499485016,
            -0.23313122987747192,
            0.07493077963590622,
            -0.04787702485918999,
            0.15317665040493011,
            0.18025952577590942,
            -0.29772183299064636,
            -0.5866102576255798,
            -0.7608237862586975,
            0.5503952503204346,
            0.5544151067733765,
            -0.009056533686816692,
            0.3110804855823517,
            -0.20759429037570953,
            -0.5514451861381531,
            0.6168713569641113,
            0.47903844714164734,
            -0.6035668253898621,
            -0.06725439429283142,
            -0.12215638160705566,
            -0.4578348398208618,
            0.14185379445552826,
            0.6138496398925781,
            0.07029607146978378,
            0.14543883502483368,
            0.8387444615364075,
            0.16400356590747833,
            0.10618335753679276,
            0.12374577671289444,
            0.02440883032977581,
            0.34760361909866333,
            0.184401273727417,
            0.15625309944152832,
            -0.24327205121517181,
            0.18300560116767883,
            0.013915588147938251,
            0.12782922387123108,
            -0.6659669876098633,
            0.6007385849952698,
            0.09062152355909348,
            0.5101187825202942,
            0.4051712155342102,
            -0.2380256950855255,
            0.36108875274658203,
            0.4179740250110626,
            -0.3082704246044159,
            -0.05633344501256943,
            0.8079760074615479,
            -0.2115340381860733,
            -0.2812262773513794,
            0.27126139402389526,
            0.4002896547317505,
            0.050573427230119705,
            -0.27470266819000244,
            -0.47252243757247925,
            0.04251337796449661,
            0.29691383242607117,
            -0.2296680212020874,
            -1.0757858753204346,
            -0.07462494820356369,
            0.38997456431388855,
            -0.0851709395647049,
            0.7825503945350647,
            -0.8043016195297241,
            -0.6881235837936401,
            -0.06820221245288849,
            -0.2156042754650116,
            -0.1878875344991684,
            0.46488499641418457,
            0.569050669670105,
            -0.45729494094848633,
            -0.10579593479633331,
            -0.46546363830566406,
            -0.7565041780471802,
            0.26971808075904846,
            -0.636620283126831,
            -0.027593091130256653,
            -0.21704329550266266,
            0.6929171681404114,
            -0.4155544638633728,
            -0.5789073705673218,
            0.29734376072883606,
            -0.20629695057868958,
            0.20220264792442322,
            -0.08972766250371933,
            0.003591669024899602,
            -0.004670067224651575,
            -0.4741159677505493,
            -0.04002698138356209,
            0.43485352396965027,
            -0.17832307517528534,
            -0.3293969929218292,
            -0.5833766460418701,
            -0.3276497721672058,
            -0.3256354033946991,
            0.08276893198490143,
            0.009932645596563816,
            -0.07687582820653915,
            0.42720475792884827,
            0.2895083427429199,
            -0.053023356944322586,
            -0.2822189927101135,
            0.3461516797542572,
            -0.5102624297142029,
            0.22414641082286835,
            -0.7650061845779419,
            -0.8188009858131409,
            0.17293575406074524,
            0.20584842562675476,
            -1.0538078546524048,
            -0.09420604258775711,
            -0.10030920058488846,
            -0.16614164412021637,
            0.8822833299636841,
            -0.006946677342057228,
            0.433450847864151,
            -0.2915442883968353,
            0.07421434670686722,
            0.36336660385131836,
            -0.2852049469947815,
            -0.027693461626768112,
            -0.12724705040454865,
            -0.11705655604600906,
            0.36477136611938477,
            -0.3339982032775879,
            -0.15071514248847961,
            -0.18686580657958984,
            0.5767137408256531,
            -0.4536719024181366,
            0.16108731925487518,
            -0.34134620428085327,
            0.3537757396697998,
            -0.00986892357468605,
            -0.10058831423521042,
            -0.3291419744491577,
            0.028180528432130814,
            0.9634740352630615,
            -0.3293791115283966,
            0.23084372282028198,
            0.2771093547344208,
            -0.3527261018753052,
            0.18004830181598663,
            0.4655545651912689,
            0.5558776259422302,
            -0.026060257107019424,
            -0.04453854635357857,
            0.6944599151611328,
            0.3910374641418457,
            0.005370644386857748,
            -0.045071858912706375,
            0.3192744851112366,
            -0.21134179830551147,
            0.2737137973308563,
            0.15838760137557983,
            0.405364066362381,
            0.5081632733345032,
            -0.2570994794368744,
            -0.663834810256958,
            -0.018332626670598984,
            -0.8633274435997009,
            -0.012123486027121544,
            -0.030486419796943665,
            0.7297477126121521,
            -0.472750186920166,
            0.10687877982854843,
            -0.0008634686819277704,
            0.205275297164917,
            -0.41825342178344727,
            -0.24479402601718903,
            0.03365635126829147,
            -0.4552959203720093,
            0.499196857213974,
            0.2951647937297821,
            0.1126936599612236,
            0.12772005796432495,
            0.3781205713748932,
            -0.008914973586797714,
            0.16747920215129852,
            -0.4999086558818817,
            0.039194654673337936,
            -0.9777252078056335,
            0.24685105681419373,
            0.2823803424835205,
            -0.33947306871414185,
            0.34500420093536377,
            0.1926250010728836,
            -0.5293612480163574,
            -0.790959894657135,
            0.24051280319690704,
            0.4453969895839691,
            -0.3853876292705536,
            0.7280423045158386,
            -0.32302021980285645,
            0.9084920883178711,
            0.6802690625190735,
            -0.1000090017914772,
            -0.20371833443641663,
            -0.6647681593894958,
            -0.5813145041465759,
            0.34577009081840515,
            0.42027547955513,
            -0.1936822533607483,
            0.4600105583667755,
            0.16962051391601562,
            0.26051825284957886,
            0.028458479791879654,
            -0.05302147567272186,
            -0.18310211598873138,
            0.2106248289346695,
            0.16436024010181427,
            0.42009714245796204,
            0.23616281151771545,
            0.4060952961444855,
            0.09696846455335617,
            -0.0356992743909359,
            0.23853379487991333,
            -0.15748733282089233,
            -0.35108062624931335,
            -0.31328174471855164,
            0.41843390464782715,
            0.24009406566619873,
            0.7044856548309326,
            0.34984418749809265,
            -0.4102896451950073,
            -0.5306543111801147,
            0.10036852955818176,
            -0.11669417470693588,
            -0.023061851039528847,
            -0.4014686048030853,
            -0.08445938676595688,
            -0.31702813506126404,
            -0.5378879308700562,
            0.5627678632736206,
            0.2040318101644516,
            0.2966085970401764,
            0.7281211614608765,
            -0.0843774601817131,
            -0.6141980886459351,
            -0.7385192513465881,
            -0.5653880834579468,
            0.333360493183136,
            0.3365391194820404,
            -0.17534787952899933,
            -0.12445495277643204,
            -0.3727922737598419,
            0.08220231533050537,
            -0.6267478466033936,
            0.01343551091849804,
            0.2257823348045349,
            -0.36202317476272583,
            -0.9174268245697021,
            0.007961963303387165,
            0.28341275453567505,
            0.8320652842521667,
            0.21428880095481873,
            -0.6228733062744141,
            0.6523988842964172,
            0.6196337938308716,
            -0.4650309681892395,
            0.4834270477294922,
            -0.22931349277496338,
            0.023651359602808952,
            0.12323254346847534,
            0.12199141830205917,
            -0.04440607130527496,
            -0.14843572676181793,
            0.07080548256635666,
            -0.28773564100265503,
            -0.7998872399330139,
            0.28007373213768005,
            -0.37113627791404724,
            -0.12712685763835907,
            0.3314821720123291,
            -0.6657548546791077,
            -0.09233131259679794,
            -0.28715837001800537,
            0.12983451783657074,
            -0.05403289198875427,
            0.5636243224143982,
            -0.3376353085041046,
            -0.009202014654874802,
            -0.05125202611088753,
            0.4948566257953644,
            0.08433875441551208,
            0.11959755420684814,
            0.013444983400404453,
            -0.45584604144096375,
            0.7454319596290588,
            0.2051931917667389,
            -0.6266289353370667,
            -0.18808138370513916,
            0.10698772966861725,
            0.40387916564941406,
            -0.4134988784790039,
            0.8452718257904053,
            -0.02904435805976391,
            -0.290358304977417,
            0.25698453187942505,
            -0.25215086340904236,
            0.06936760246753693,
            -0.03550174459815025,
            0.22927887737751007,
            -1.0134443044662476,
            0.38327035307884216,
            0.25776463747024536,
            0.2180226594209671,
            -0.18627963960170746,
            0.43063992261886597,
            -0.11812419444322586,
            0.7680028080940247,
            0.3746732473373413,
            0.10501900315284729,
            0.08354946970939636,
            -0.3416152596473694,
            -0.41559863090515137,
            0.3059858977794647,
            -0.8837755918502808,
            0.2270958125591278,
            -0.3802594542503357,
            -0.04205881804227829,
            0.4931837022304535,
            -0.43954846262931824,
            -0.021296456456184387,
            0.38879460096359253,
            0.3117092549800873,
            -0.010240422561764717,
            -0.19846481084823608,
            0.9313316941261292,
            0.40820378065109253,
            -0.2176915556192398,
            0.006377199664711952,
            0.022973259910941124,
            0.7594349384307861,
            -0.3564295172691345,
            -0.1069260835647583,
            0.33604487776756287,
            -0.22625242173671722,
            -0.3506353795528412,
            -0.34123143553733826,
            0.18592709302902222,
            0.19261884689331055,
            0.16532693803310394,
            -0.6651496887207031,
            0.06602271646261215,
            -0.006705205421894789,
            -0.15663206577301025,
            -0.2019738107919693,
            0.29531651735305786,
            -0.34127745032310486,
            0.09504834562540054,
            -0.027071619406342506,
            0.12558208405971527,
            -0.9559042453765869,
            -0.055401138961315155,
            0.31647786498069763,
            -0.13620123267173767,
            0.7243645191192627,
            -0.11864274740219116,
            0.05447159707546234,
            0.24379998445510864,
            0.03513346239924431,
            -0.5058481097221375,
            0.08499214053153992,
            0.7133675217628479,
            -0.3443218469619751,
            -0.07516799122095108,
            0.4712393581867218,
            -0.7348475456237793,
            -0.5305038094520569,
            0.48491358757019043,
            0.469153493642807,
            -0.02398371323943138,
            0.6311368942260742,
            -0.1485712230205536,
            0.06424746662378311,
            0.5073822140693665,
            0.030622398480772972,
            0.1737506240606308,
            0.5507239103317261,
            -0.3912636637687683,
            0.28128090500831604,
            0.012439211830496788,
            -0.4761006534099579,
            -0.16219229996204376,
            -0.06663811206817627,
            0.6064090728759766,
            -0.11879341304302216,
            0.2064676135778427,
            -0.18637074530124664,
            -0.12721166014671326,
            -0.9124947190284729,
            0.11921389400959015,
            -0.14633961021900177,
            -0.2642728388309479,
            -0.20830632746219635,
            0.33404091000556946,
            -0.4516666531562805,
            -0.6013169884681702,
            0.1099703386425972,
            -0.07799982279539108,
            -0.3770295977592468,
            0.024725092574954033,
            0.16673754155635834,
            0.010045547038316727,
            -0.37315690517425537,
            -0.062053631991147995,
            0.2053380012512207,
            0.1209140494465828,
            -0.865017294883728,
            -0.056473907083272934,
            0.08906766772270203,
            0.326917439699173,
            0.7739946842193604,
            0.43664878606796265,
            -0.20553046464920044,
            0.3982798159122467,
            -0.008306819014251232,
            -0.04560508206486702,
            -0.6597461700439453,
            0.6555759310722351,
            -0.7027437686920166,
            0.7467830181121826,
            -0.1421281099319458,
            -0.19024546444416046,
            0.47144395112991333,
            -0.3527005910873413,
            -0.5905829668045044,
            -0.07854482531547546,
            -0.7134636044502258,
            0.9841886162757874,
            0.41770195960998535,
            -0.007903599180281162,
            -0.4190583825111389,
            -0.6170704960823059,
            0.3769993782043457,
            -0.41788384318351746,
            -0.023959897458553314,
            -0.451260507106781,
            -0.4560278654098511,
            0.6611272692680359,
            -0.8387904763221741,
            -0.5641899108886719,
            -0.40599891543388367,
            -0.13820676505565643,
            0.18874390423297882,
            0.29542261362075806,
            0.9693631529808044,
            1.0453474521636963,
            -0.4714154601097107,
            -0.6737620234489441,
            -0.35360631346702576,
            0.06819409132003784,
            0.5834755301475525,
            -0.2291148453950882,
            -0.24399106204509735,
            0.34413474798202515,
            0.6068117022514343,
            0.3882032632827759,
            -0.297610342502594,
            -0.35668471455574036,
            0.29134103655815125,
            0.033894170075654984,
            0.186726912856102,
            -0.4015979468822479,
            -1.0153172016143799,
            0.18511396646499634,
            0.13217490911483765,
            -0.04171440750360489,
            0.2546662986278534,
            0.5851858854293823,
            -0.3122243881225586,
            0.6590774059295654,
            0.6570034623146057,
            0.092836894094944,
            -0.6502375602722168,
            -0.2527577877044678,
            -0.3082345724105835,
            0.23941254615783691,
            0.36724168062210083,
            0.7954443097114563,
            -0.3071618676185608,
            -0.5894225835800171,
            -0.14698998630046844,
            0.17667829990386963,
            0.15230199694633484,
            -0.4114551842212677,
            -0.15317116677761078,
            -0.1200651004910469,
            1.119117259979248,
            1.0462335348129272,
            0.3582371771335602,
            -0.19341662526130676,
            0.33043286204338074,
            0.31478506326675415,
            0.4320923388004303,
            0.1408272087574005,
            0.26125961542129517,
            0.17070536315441132,
            0.20350109040737152,
            -0.8126437664031982,
            0.5536593794822693,
            0.039699405431747437,
            -0.08409088850021362,
            0.1951441615819931,
            -0.21827223896980286,
            0.1465749740600586,
            0.16925837099552155,
            0.10909342020750046,
            -0.6040463447570801,
            0.5285109877586365,
            -0.04485589638352394,
            0.3514035940170288,
            -0.5970363616943359,
            0.42759349942207336,
            0.34450340270996094,
            -0.04577028006315231,
            -0.513395369052887,
            -0.08011449873447418,
            -0.1134951189160347,
            -0.5281530022621155,
            -0.05683567002415657,
            0.1667560636997223,
            0.1592230349779129,
            0.14285221695899963,
            -0.758578360080719,
            -0.7900074124336243,
            -0.10895530879497528,
            0.8373720645904541,
            0.8730828762054443,
            0.12048208713531494,
            0.02916284091770649,
            0.08838070183992386,
            0.6349804997444153,
            0.43834996223449707,
            -0.1842578947544098,
            0.05705047771334648,
            -0.6715177893638611,
            0.15552908182144165,
            -0.2018498033285141,
            0.4518449306488037,
            0.2869096100330353,
            0.4700612425804138,
            -0.19418250024318695,
            0.667630672454834,
            0.326822966337204,
            -0.5744593739509583,
            0.6883338093757629,
            0.3740127980709076,
            0.14967092871665955,
            -0.4201323688030243,
            -0.30083420872688293,
            -0.24002104997634888,
            0.024442942813038826,
            -0.7886573076248169,
            0.02990231290459633,
            0.17908810079097748,
            0.427005410194397,
            -0.4711046814918518,
            -0.05821359530091286,
            0.3244370222091675,
            -0.19208455085754395,
            -0.05003555119037628,
            0.09803667664527893,
            -0.1102214902639389,
            -0.04678645357489586,
            0.38101163506507874,
            -0.15855816006660461,
            -0.25011634826660156,
            0.4347582459449768,
            -0.16069084405899048,
            -0.12106805294752121,
            0.642996072769165,
            0.10265275090932846,
            0.414203941822052,
            -0.2844843566417694,
            -0.07486575841903687,
            0.21816910803318024,
            -0.1452566534280777,
            0.4227730631828308,
            0.14172996580600739,
            0.4769171178340912,
            0.17998820543289185,
            -0.08077831566333771,
            -0.0909503847360611,
            -0.30836325883865356,
            -0.19712358713150024,
            -0.2139686644077301,
            0.2768188416957855,
            -0.2513906955718994,
            0.7195950746536255,
            -0.019169999286532402,
            0.22164002060890198,
            0.0013793657999485731,
            -0.1544617861509323,
            -0.08342049270868301,
            -0.2916744649410248,
            0.06302616745233536,
            0.21621869504451752,
            0.16560791432857513,
            -0.23056045174598694,
            -0.4602414071559906,
            -0.3271017372608185,
            0.4082457721233368,
            -0.1596379280090332,
            0.5324310064315796,
            -0.692186176776886,
            0.35423150658607483,
            -0.28244850039482117,
            0.2611481249332428,
            -0.5476794242858887,
            0.11219722777605057,
            0.11171036213636398,
            0.2945888340473175,
            0.18751193583011627,
            0.6040874719619751,
            0.3369040787220001,
            0.2176983505487442,
            -0.13924165070056915,
            0.052167121320962906,
            0.36096736788749695,
            0.2626132369041443,
            0.04338068515062332,
            0.25205349922180176,
            0.7514328360557556,
            0.007335486821830273,
            0.10335727781057358,
            0.758872926235199,
            -0.25450894236564636,
            -0.05467677861452103,
            -0.1827905923128128,
            -0.2190266102552414,
            0.026873478665947914,
            -0.16120383143424988,
            0.5025489330291748,
            -1.3206095695495605,
            0.011847621761262417,
            0.5486935973167419,
            -0.18221232295036316,
            -0.2855481803417206,
            -0.5013852119445801,
            0.6779594421386719,
            0.0791686475276947,
            0.5205896496772766,
            -0.5164886116981506,
            0.29098448157310486,
            0.3865325450897217,
            -0.23138630390167236,
            0.4437079131603241,
            -0.24406291544437408,
            0.9221066832542419,
            -0.47233912348747253,
            0.16080424189567566,
            0.13364402949810028,
            0.5244064927101135,
            0.687566876411438,
            0.09951252490282059,
            -0.15885451436042786,
            -0.30573317408561707,
            0.33387115597724915,
            0.8299092054367065,
            -0.8959775567054749,
            -0.03852785378694534,
            -0.38096460700035095,
            0.6068812012672424,
            0.1595684289932251,
            -0.22991344332695007,
            -0.11896321922540665,
            -0.23539024591445923,
            -0.09703001379966736,
            -0.13990908861160278,
            0.3706672489643097,
            -0.31168994307518005,
            -0.2657126188278198,
            0.38830217719078064,
            0.11527292430400848,
            -0.5673118829727173,
            -0.10291841626167297,
            0.03428215533494949,
            -0.7059093117713928,
            0.6870492696762085,
            -0.2591441571712494,
            -0.20737126469612122,
            0.24884259700775146,
            0.11563573777675629,
            -0.20665998756885529,
            -0.6216560006141663,
            0.20471805334091187,
            0.09775303304195404,
            0.1412813365459442,
            -0.477033406496048,
            -0.18636423349380493,
            -0.07806272059679031,
            -0.20573368668556213,
            0.1516490876674652,
            -0.44879695773124695,
            -0.3587547838687897,
            -0.02172982320189476,
            -0.47168684005737305,
            0.3144388496875763,
            -0.521443247795105,
            0.1890934407711029,
            0.3278243839740753,
            0.15866348147392273,
            0.11768453568220139,
            0.15105688571929932,
            -0.00046838668640702963,
            0.07957453280687332,
            -0.5366932153701782,
            0.09657600522041321,
            0.7231138348579407,
            -1.0144857168197632,
            -0.23315644264221191,
            0.16423168778419495,
            -0.07594049721956253,
            -0.08918467164039612,
            0.07057074457406998,
            0.6496168971061707,
            0.5009250640869141,
            -0.05370635911822319,
            -0.7459275126457214,
            -0.36902230978012085,
            -0.21072998642921448,
            -0.6379491686820984,
            -0.11119326949119568,
            0.08950874209403992,
            -0.6930263638496399,
            0.033869724720716476,
            -0.12156013399362564,
            0.7842553853988647,
            0.11105680465698242,
            -1.0689353942871094,
            -0.6111453771591187,
            -0.33995506167411804,
            -0.032601248472929,
            0.041751328855752945,
            0.16158927977085114,
            -0.3093876838684082,
            0.2377718687057495,
            0.19744381308555603,
            0.8271771669387817,
            -0.6193535923957825,
            0.28059402108192444,
            0.08465422689914703,
            -0.31603553891181946,
            0.5259829759597778,
            -0.026278728619217873,
            -0.24171261489391327,
            -0.2692698836326599,
            0.30241286754608154,
            -0.1369214802980423,
            0.26006099581718445,
            -0.2343994677066803,
            0.2170654684305191,
            -0.4379836320877075,
            0.3063056170940399,
            -0.1041734591126442,
            -0.019059626385569572,
            0.35061249136924744,
            -0.9256690740585327,
            -0.6980651021003723,
            -0.08332063257694244,
            0.19287987053394318,
            0.022132249549031258,
            0.038969289511442184,
            -0.12271669507026672,
            -0.12920688092708588,
            -0.03644822910428047,
            -0.3158850371837616,
            0.6140871047973633,
            0.24187174439430237,
            0.03029496595263481,
            -0.6587358117103577,
            -0.3877573609352112,
            0.8728627562522888,
            -0.46932488679885864,
            0.1078200563788414,
            0.6871193051338196,
            -0.27767008543014526,
            0.461930513381958,
            0.2755521237850189,
            0.16741986572742462,
            -0.03424322232604027,
            -0.27840808033943176,
            0.5199481844902039,
            -0.5676647424697876,
            -0.023935694247484207,
            -0.17096148431301117,
            0.11224919557571411,
            -0.05257955938577652,
            -0.014310356229543686,
            -0.20934227108955383,
            0.3555724024772644,
            0.07194926589727402,
            0.37356677651405334,
            0.4549693465232849,
            -0.35365012288093567,
            0.010751309804618359,
            0.1798270344734192,
            -0.18532612919807434,
            0.637588381767273,
            -1.001488447189331,
            -0.5287880301475525,
            -0.28686901926994324,
            0.024874145165085793,
            -0.23184247314929962,
            -0.5040032267570496,
            -0.38518670201301575,
            -0.48189616203308105,
            -0.11793622374534607,
            -0.18009881675243378,
            0.17109361290931702,
            -0.29456719756126404,
            -0.03861799091100693,
            0.5719954371452332,
            -0.9550970792770386,
            0.2692021131515503,
            0.20975814759731293,
            0.18517933785915375,
            0.03471662476658821,
            0.7693893909454346,
            0.34009596705436707,
            0.2657076418399811,
            -0.030222753062844276,
            0.23821590840816498,
            -0.5542672872543335,
            -0.00393869960680604,
            -0.10062804073095322,
            0.09324148297309875,
            -0.3630404770374298,
            0.011528966948390007,
            0.7485033273696899,
            0.04393908008933067,
            -0.414321631193161,
            0.1812489628791809,
            0.048838142305612564,
            0.3711521327495575,
            -0.03502713888883591,
            -0.8125508427619934,
            0.13166052103042603,
            -0.1978292018175125,
            -0.789141833782196,
            0.04143555089831352,
            0.3996519148349762,
            -0.03766506537795067,
            0.110408715903759,
            -0.8220940232276917,
            -0.9336612820625305,
            0.12043718248605728,
            0.09418763965368271,
            0.558819591999054,
            0.1709413081407547,
            0.0026171463541686535,
            -0.02027706243097782,
            -0.8705466389656067,
            -0.4362037181854248,
            0.2837303876876831,
            0.0725288912653923,
            0.3686257600784302,
            0.10746286809444427,
            0.05132138356566429,
            -0.24718335270881653,
            0.5006450414657593,
            -0.986201822757721,
            -0.1582416296005249,
            -0.15235841274261475,
            0.09931888431310654,
            -0.0587054081261158,
            0.11029097437858582,
            0.44365566968917847,
            0.5340969562530518,
            -0.2609863579273224,
            0.6767538189888,
            -0.35622236132621765,
            0.006685134023427963,
            -0.22112128138542175,
            0.10514029860496521,
            0.26490962505340576,
            0.6797425150871277,
            -0.40849071741104126,
            0.2149396538734436,
            -0.025594370439648628,
            -0.21208520233631134,
            0.13285155594348907,
            0.6873643398284912,
            -0.05219295993447304,
            0.30199840664863586,
            0.6757975220680237,
            -0.015883956104516983,
            0.47664493322372437,
            -0.588622510433197,
            -0.26577258110046387,
            0.08800800889730453,
            -0.22322317957878113,
            0.12664194405078888,
            0.27441662549972534,
            -0.24959735572338104,
            0.20171399414539337,
            -0.6132971048355103,
            -0.26623475551605225,
            -0.5978553891181946,
            0.9494639039039612,
            0.32227614521980286,
            -0.04157865419983864,
            0.1930759698152542,
            0.7912816405296326,
            -0.625478982925415,
            -0.5142568349838257,
            -0.360281378030777,
            0.01567203179001808,
            -0.44009432196617126,
            -0.3544473946094513,
            0.3209415376186371,
            -0.801386296749115,
            -0.20402762293815613,
            0.03546562045812607,
            0.13173218071460724,
            -0.4790390133857727,
            -0.5932571291923523,
            -0.957902729511261,
            -0.6028214693069458,
            -0.3170520067214966,
            0.3158126771450043,
            -0.6312332153320312,
            0.179973304271698,
            -0.17864437401294708,
            -0.3761984407901764,
            0.03802996873855591,
            -0.41236409544944763,
            -0.5541235208511353,
            -0.005027507431805134,
            0.3952682316303253,
            0.34546419978141785,
            0.19322416186332703,
            -0.312346875667572,
            0.4183410108089447,
            -0.4827018976211548,
            0.12100476771593094,
            -0.7046714425086975,
            -0.16192765533924103,
            -0.3776441514492035,
            0.22225113213062286,
            0.09785061329603195,
            0.4939081370830536,
            0.532200276851654,
            -0.9729152321815491,
            0.6365166306495667,
            0.2931492328643799,
            -0.18136686086654663,
            -0.16424298286437988,
            -0.4767746031284332,
            -0.20252501964569092,
            0.7916309237480164,
            -0.09925171732902527,
            0.5680163502693176,
            0.0002770146820694208,
            0.8420591950416565,
            1.07551908493042,
            0.20521816611289978,
            -0.3102271556854248,
            0.12417947500944138,
            0.6297944188117981,
            0.34591609239578247,
            0.38906073570251465,
            -0.05737844854593277,
            -0.6799075603485107,
            0.04821087047457695,
            -0.7126803398132324,
            0.6454874277114868,
            0.09670013934373856,
            0.3264561891555786,
            0.08701594918966293,
            0.11004907637834549,
            0.19358205795288086,
            0.7420081496238708,
            -0.028652267530560493,
            0.28423815965652466,
            -0.17348769307136536,
            0.055533140897750854,
            0.20460271835327148,
            -0.00042620321619324386,
            -0.39296260476112366,
            0.4543975591659546,
            0.3269018530845642,
            -0.056590426713228226,
            -0.2667562961578369,
            -1.0337058305740356,
            -0.012195413932204247,
            0.037764426320791245,
            0.511170506477356,
            -0.16856378316879272,
            0.8942597508430481,
            -0.06874275952577591,
            -0.5669468641281128,
            -0.38487979769706726,
            0.21022860705852509,
        ],
    ]
)
b_h = np.array([-1.0337257385253906, 0.3351593613624573])
w_o = np.array([[0.7582084536552429, -0.9661162495613098]])
b_o = np.array(3.7579023838043213)


class PredictorError(Exception):
    def __init__(self, msg, code):
        self.msg = msg
        self.code = code

    def __str__(self):
        return self.msg


def __convert(cell):
    value = str(cell)
    if value == random_filler_value:
        value = ""
    try:
        result = int(value)
        return result
    except ValueError:
        try:
            result = float(value)
            if math.isnan(result):
                raise PredictorError("NaN value found. Aborting.", code=1)
            return result
        except ValueError:
            result = binascii.crc32(value.encode("utf8")) % (1 << 32)
            return result
        except Exception as e:
            raise e


def __get_key(val, dictionary):
    if dictionary == {}:
        return val
    for key, value in dictionary.items():
        if val == value:
            return key
    if val not in dictionary.values():
        raise PredictorError(f"Label {val} key does not exist", code=2)


def __confusion_matrix(y_true, y_pred, json):
    stats = {}
    labels = np.array(list(mapping.keys()))
    sample_weight = np.ones(y_true.shape[0], dtype=np.int64)
    for class_i in range(n_classes):
        class_i_label = __get_key(class_i, mapping)
        stats[int(class_i)] = {}
        class_i_indices = np.argwhere(y_true == class_i_label)
        not_class_i_indices = np.argwhere(y_true != class_i_label)
        # None represents N/A in this case
        stats[int(class_i)]["TP"] = TP = (
            int(np.sum(y_pred[class_i_indices] == class_i_label))
            if class_i_indices.size > 0
            else None
        )
        stats[int(class_i)]["FN"] = FN = (
            int(np.sum(y_pred[class_i_indices] != class_i_label))
            if class_i_indices.size > 0
            else None
        )
        stats[int(class_i)]["TN"] = TN = (
            int(np.sum(y_pred[not_class_i_indices] != class_i_label))
            if not_class_i_indices.size > 0
            else None
        )
        stats[int(class_i)]["FP"] = FP = (
            int(np.sum(y_pred[not_class_i_indices] == class_i_label))
            if not_class_i_indices.size > 0
            else None
        )
        if TP is None or FN is None or (TP + FN == 0):
            stats[int(class_i)]["TPR"] = None
        else:
            stats[int(class_i)]["TPR"] = TP / (TP + FN)
        if TN is None or FP is None or (TN + FP == 0):
            stats[int(class_i)]["TNR"] = None
        else:
            stats[int(class_i)]["TNR"] = TN / (TN + FP)
        if TP is None or FP is None or (TP + FP == 0):
            stats[int(class_i)]["PPV"] = None
        else:
            stats[int(class_i)]["PPV"] = TP / (TP + FP)
        if TN is None or FN is None or (TN + FN == 0):
            stats[int(class_i)]["NPV"] = None
        else:
            stats[int(class_i)]["NPV"] = TN / (TN + FN)
        if TP is None or FP is None or FN is None or (TP + FP + FN == 0):
            stats[int(class_i)]["F1"] = None
        else:
            stats[int(class_i)]["F1"] = (2 * TP) / (2 * TP + FP + FN)
        if TP is None or FP is None or FN is None or (TP + FP + FN == 0):
            stats[int(class_i)]["TS"] = None
        else:
            stats[int(class_i)]["TS"] = TP / (TP + FP + FN)

    if not report_cmat:
        return np.array([]), stats

    label_to_ind = {label: i for i, label in enumerate(labels)}
    y_pred = np.array([label_to_ind.get(x, n_classes + 1) for x in y_pred])
    y_true = np.array([label_to_ind.get(x, n_classes + 1) for x in y_true])

    ind = np.logical_and(y_pred < n_classes, y_true < n_classes)
    y_pred = y_pred[ind]
    y_true = y_true[ind]
    sample_weight = sample_weight[ind]

    cm = coo_matrix(
        (sample_weight, (y_true, y_pred)), shape=(n_classes, n_classes), dtype=np.int64
    ).toarray()
    with np.errstate(all="ignore"):
        cm = np.nan_to_num(cm)

    return cm, stats


def __preprocess_and_clean_in_memory(arr):
    clean_arr = np.zeros((len(arr), len(important_idxs)))
    for i, row in enumerate(arr):
        try:
            row_used_cols_only = [row[i] for i in important_idxs]
        except IndexError:
            error_str = f"The input has shape ({len(arr)}, {len(row)}) but the expected shape is (*, {len(ignorecolumns) + len(important_idxs)})."
            if len(arr) == num_attr and len(arr[0]) != num_attr:
                error_str += "\n\nNote: You may have passed an input directly to 'preprocess_and_clean_in_memory' or 'predict_in_memory' "
                error_str += "rather than as an element of a list. Make sure that even single instances "
                error_str += "are enclosed in a list. Example: predict_in_memory(0) is invalid but "
                error_str += "predict_in_memory([0]) is valid."
            raise PredictorError(error_str, 3)
        clean_arr[i] = [float(__convert(field)) for field in row_used_cols_only]
    return clean_arr


def __classify(arr, return_probabilities=False):
    h = np.dot(arr, w_h.T) + b_h
    relu = np.maximum(h, np.zeros_like(h))
    out = np.dot(relu, w_o.T) + b_o
    if return_probabilities:
        exp_o = np.zeros((out.shape[0],))
        idxs_negative = np.argwhere(out < 0.0).reshape(-1)
        if idxs_negative.shape[0] > 0:
            exp_o[idxs_negative] = 1.0 - np.exp(
                -np.fmax(out[idxs_negative], 0)
            ).reshape(-1) / (1.0 + np.exp(-np.abs(out[idxs_negative]))).reshape(-1)
        idxs_positive = np.argwhere(out >= 0.0).reshape(-1)
        if idxs_positive.shape[0] > 0:
            exp_o[idxs_positive] = np.exp(np.fmin(out[idxs_positive], 0)).reshape(
                -1
            ) / (1.0 + np.exp(-np.abs(out[idxs_positive]))).reshape(-1)
        exp_o = exp_o.reshape(-1, 1)
        output = np.concatenate((1.0 - exp_o, exp_o), axis=1)
    else:
        output = (out >= 0).astype("int").reshape(-1)
    return output


def __validate_kwargs(kwargs):
    for key in kwargs:

        if key not in ["return_probabilities"]:
            raise PredictorError(
                f"{key} is not a keyword argument for Brainome's {classifier_type} predictor. Please see the documentation.",
                4,
            )


def __validate_data(row_or_arr, validate, row_num=None):
    if validate:
        expected_columns = expected_feature_cols + 1
    else:
        expected_columns = expected_feature_cols

    input_is_array = isinstance(row_or_arr, np.ndarray)
    n_cols = row_or_arr.shape[1] if input_is_array else len(row_or_arr)

    if n_cols != expected_columns:

        if row_num is None:
            err_str = f"Your data contains {n_cols} columns but {expected_columns} are required."
        else:
            err_str = f"At row {row_num}, your data contains {n_cols} columns but {expected_columns} are required."

        if validate:
            err_str += " The predictor's validate() method works on data that has the same columns in the same order as were present in the training CSV."
            err_str += " This includes the target column and features that are not used by the model but existed in the training CSV."
            if n_cols == 1 + len(important_idxs):
                err_str += f" We suggest confirming that the {expected_feature_cols - len(important_idxs)} unused features are present in the data."
            elif n_cols == len(important_idxs):
                err_str += f" We suggest confirming that the {expected_feature_cols - len(important_idxs)} unused features are present in the data as well as the target column. "
            elif n_cols == len(important_idxs) + len(ignore_idxs):
                err_str += " We suggest confirming that the target column present in the data. "
            err_str += " To make predictions, see the predictor's predict() method."
        else:
            err_str += " The predictor's predict() method works on data that has the same feature columns in the same relative order as were present in the training CSV."
            err_str += " This DOES NOT include the target column but DOES include features that are not used by the model but existed in the training CSV."
            if n_cols == 1 + len(important_idxs):
                err_str += f" We suggest confirming that the {expected_feature_cols - len(important_idxs)} unused features are present in the data and that the target column is not present."
            elif n_cols == len(important_idxs):
                err_str += f" We suggest confirming that the {expected_feature_cols - len(important_idxs)} unused features are present in the data."
            elif n_cols == 1 + len(important_idxs) + len(ignore_idxs):
                err_str += (
                    " We suggest confirming that the target column is not present."
                )
            err_str += " To receive a performance summary, instead of make predictions, see the predictor's validate() method."

        raise PredictorError(err_str, 5)

    else:

        if not input_is_array:
            return row_or_arr


def __write_predictions(arr, header, headerless, trim, outfile=None):
    predictions = predict(arr)
    buff = []

    if not headerless:
        if trim:
            header = ",".join([header[i] for i in important_idxs] + ["Prediction"])
        else:
            header = ",".join(header.tolist() + ["Prediction"])
        if outfile is None:
            print(header)
        else:
            print(header, file=outfile)

    for row, prediction in zip(arr, predictions):
        if trim:
            row = [
                f'"{row[i]}",' if "," in row[i] else f"{row[i]},"
                for i in important_idxs
            ]
        else:
            row = [f'"{field}",' if "," in field else f"{field}," for field in row]
        row.append(prediction)
        buff.extend(row)
        if len(buff) >= IOBUFF:
            if outfile is None:
                print("".join(buff))
            else:
                print("".join(buff), file=outfile)
            buff = []
        else:
            buff.append("\n")
    if len(buff) > 0:
        if outfile is None:
            print("".join(buff))
        else:
            print("".join(buff), file=outfile)


def load_data(csvfile, headerless, validate):
    """
    Parameters
    ----------
    csvfile : str
        The path to the CSV file containing the data.

    headerless : bool
        True if the CSV does not contain a header.

    validate : bool
        True if the data should be loaded to be used by the predictor's validate() method.
        False if the data should be loaded to be used by the predictor's predict() method.

    Returns
    -------
    arr : np.ndarray
        The data (observations and labels) found in the CSV without any header.

    data : np.ndarray or NoneType
        None if validate is False, otherwise the observations (data without the labels) found in the CSV.

    labels : np.ndarray or NoneType
        None if the validate is False, otherwise the labels found in the CSV.

    header : np.ndarray or NoneType
        None if the CSV is headerless, otherwise the header.
    """

    with open(csvfile, "r", encoding="utf-8") as csvinput:
        arr = np.array(
            [
                __validate_data(row, validate, row_num=i)
                for i, row in enumerate(csv.reader(csvinput))
                if row != []
            ],
            dtype=str,
        )
    if headerless:
        header = None
    else:
        header = arr[0]
        arr = arr[1:]
    if validate:
        labels = np.char.strip(arr[:, target_column], chars=" \"'")
        feature_columns = [i for i in range(arr.shape[1]) if i != target_column]
        data = arr[:, feature_columns]
    else:
        data, labels = None, None

    if validate and ignorelabels != []:
        idxs_to_keep = np.argwhere(
            np.logical_not(np.isin(labels, ignorelabels))
        ).reshape(-1)
        labels = labels[idxs_to_keep]
        data = data[idxs_to_keep]

    return arr, data, labels, header


def predict(arr, remap=True, **kwargs):
    """
    Parameters
    ----------
    arr : list[list]
        An array of inputs to be cleaned by 'preprocess_and_clean_in_memory'. This
        should contain all the features that were present in the training data,
        regardless of whether or not they are used by the model, with the same
        relative order as in the training data. There should be no target column.


    remap : bool
        If True and 'return_probs' is False, remaps the output to the original class
        label. If 'return_probs' is True this instead adds a header indicating which
        original class label each column of output corresponds to.

    **kwargs :
        return_probabilities : bool
            If true, return class membership probabilities instead of classifications.

    Returns
    -------
    output : np.ndarray

        A numpy array of
            1. Class predictions if 'return_probabilities' is False.
            2. Class probabilities if 'return_probabilities' is True.

    """
    if not isinstance(arr, np.ndarray) and not isinstance(arr, list):
        raise PredictorError(
            f"Data must be provided to 'predict' and 'validate' as a list or np.ndarray, but an input of type {type(arr).__name__} was found.",
            6,
        )
    if isinstance(arr, list):
        arr = np.array(arr, dtype=str)

    kwargs = kwargs or {}
    __validate_kwargs(kwargs)
    __validate_data(arr, False)
    remove_bad_chars = (
        lambda x: str(x)
        .replace('"', "")
        .replace(",", "")
        .replace("(", "")
        .replace(")", "")
        .replace("'", "")
    )
    arr = [[remove_bad_chars(field) for field in row] for row in arr]
    arr = __preprocess_and_clean_in_memory(arr)

    output = __classify(arr, **kwargs)

    if remap:
        if kwargs.get("return_probabilities"):
            header = np.array(
                [__get_key(i, mapping) for i in range(output.shape[1])], dtype=str
            ).reshape(1, -1)
            output = np.concatenate((header, output), axis=0)
        else:
            output = np.array([__get_key(prediction, mapping) for prediction in output])

    return output


def validate(arr, labels):
    """
    Parameters
    ----------
    cleanarr : np.ndarray
        An array of float values that has undergone each pre-
        prediction step.

    Returns
    -------
    count : int
        A count of the number of instances in cleanarr.

    correct_count : int
        A count of the number of correctly classified instances in
        cleanarr.

    numeachclass : dict
        A dictionary mapping each class to its number of instances.

    outputs : np.ndarray
        The output of the predictor's '__classify' method on cleanarr.
    """
    predictions = predict(arr)
    correct_count = int(np.sum(predictions.reshape(-1) == labels.reshape(-1)))
    count = predictions.shape[0]

    class_0, class_1 = __get_key(0, mapping), __get_key(1, mapping)
    num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0 = 0, 0, 0, 0, 0, 0
    num_TP = int(
        np.sum(
            np.logical_and(
                predictions.reshape(-1) == class_1, labels.reshape(-1) == class_1
            )
        )
    )
    num_TN = int(
        np.sum(
            np.logical_and(
                predictions.reshape(-1) == class_0, labels.reshape(-1) == class_0
            )
        )
    )
    num_FN = int(
        np.sum(
            np.logical_and(
                predictions.reshape(-1) == class_0, labels.reshape(-1) == class_1
            )
        )
    )
    num_FP = int(
        np.sum(
            np.logical_and(
                predictions.reshape(-1) == class_1, labels.reshape(-1) == class_0
            )
        )
    )
    num_class_0 = int(np.sum(labels.reshape(-1) == class_0))
    num_class_1 = int(np.sum(labels.reshape(-1) == class_1))
    return (
        count,
        correct_count,
        num_TP,
        num_TN,
        num_FP,
        num_FN,
        num_class_1,
        num_class_0,
        predictions,
    )


def __main():
    parser = argparse.ArgumentParser(
        description="Predictor trained on " + str(TRAINFILE)
    )
    parser.add_argument(
        "csvfile", type=str, help="CSV file containing test set (unlabeled)."
    )
    parser.add_argument(
        "-validate",
        action="store_true",
        help="Validation mode. csvfile must be labeled. Output is classification statistics rather than predictions.",
    )
    parser.add_argument(
        "-headerless",
        help="Do not treat the first line of csvfile as a header.",
        action="store_true",
    )
    parser.add_argument(
        "-json", action="store_true", default=False, help="report measurements as json"
    )
    parser.add_argument(
        "-trim",
        action="store_true",
        help="If true, the prediction will not output ignored columns.",
    )
    args = parser.parse_args()
    faulthandler.enable()

    arr, data, labels, header = load_data(
        csvfile=args.csvfile, headerless=args.headerless, validate=args.validate
    )

    if not args.validate:
        __write_predictions(arr, header, args.headerless, args.trim)
    else:

        (
            count,
            correct_count,
            num_TP,
            num_TN,
            num_FP,
            num_FN,
            num_class_1,
            num_class_0,
            preds,
        ) = validate(data, labels)

        classcounts = np.bincount(
            np.array([mapping[label.strip()] for label in labels], dtype="int32")
        ).reshape(-1)
        class_balance = (
            (classcounts[np.argwhere(classcounts > 0)] / arr.shape[0])
            .reshape(-1)
            .tolist()
        )
        best_guess = round(100.0 * np.max(class_balance), 2)
        H = float(
            -1.0
            * sum(
                [
                    class_balance[i] * math.log(class_balance[i]) / math.log(2)
                    for i in range(len(class_balance))
                ]
            )
        )
        modelacc = int(float(correct_count * 10000) / count) / 100.0
        mtrx, stats = __confusion_matrix(
            np.array(labels).reshape(-1), np.array(preds).reshape(-1), args.json
        )

        if args.json:
            json_dict = {
                "instance_count": count,
                "classifier_type": classifier_type,
                "classes": n_classes,
                "number_correct": correct_count,
                "accuracy": {
                    "best_guess": (best_guess / 100),
                    "improvement": (modelacc - best_guess) / 100,
                    "model_accuracy": (modelacc / 100),
                },
                "model_capacity": model_cap,
                "generalization_ratio": int(float(correct_count * 100) / model_cap)
                / 100.0
                * H,
                "model_efficiency": int(100 * (modelacc - best_guess) / model_cap)
                / 100.0,
                "shannon_entropy_of_labels": H,
                "class_balance": class_balance,
                "confusion_matrix": mtrx.tolist(),
                "multiclass_stats": stats,
            }

            print(json.dumps(json_dict))
        else:
            pad = (
                lambda s, length, pad_right: str(s) + " " * max(0, length - len(str(s)))
                if pad_right
                else " " * max(0, length - len(str(s))) + str(s)
            )
            labels = np.array(list(mapping.keys())).reshape(-1, 1)
            max_class_name_len = max([len(clss) for clss in mapping.keys()] + [7])

            max_TP_len = max([len(str(stats[key]["TP"])) for key in stats.keys()] + [2])
            max_FP_len = max([len(str(stats[key]["FP"])) for key in stats.keys()] + [2])
            max_TN_len = max([len(str(stats[key]["TN"])) for key in stats.keys()] + [2])
            max_FN_len = max([len(str(stats[key]["FN"])) for key in stats.keys()] + [2])

            cmat_template_1 = "    {} | {}"
            cmat_template_2 = "    {} | " + " {} " * n_classes
            acc_by_class_template_1 = "    {} | {}  {}  {}  {}  {}  {}  {}  {}  {}  {}"

            acc_by_class_lengths = [
                max_class_name_len,
                max_TP_len,
                max_FP_len,
                max_TN_len,
                max_FN_len,
                7,
                7,
                7,
                7,
                7,
                7,
            ]
            acc_by_class_header_fields = [
                "target",
                "TP",
                "FP",
                "TN",
                "FN",
                "TPR",
                "TNR",
                "PPV",
                "NPV",
                "F1",
                "TS",
            ]
            print("Classifier Type:                    Neural Network")

            print(f"System Type:                        {n_classes}-way classifier\n")

            print("Accuracy:")
            print("    Best-guess accuracy:            {:.2f}%".format(best_guess))
            print(
                "    Model accuracy:                 {:.2f}%".format(modelacc)
                + " ("
                + str(int(correct_count))
                + "/"
                + str(count)
                + " correct)"
            )
            print(
                "    Improvement over best guess:    {:.2f}%".format(
                    modelacc - best_guess
                )
                + " (of possible "
                + str(round(100 - best_guess, 2))
                + "%)\n"
            )

            print("Model capacity (MEC):               {:.0f} bits".format(model_cap))
            print(
                "Generalization ratio:               {:.2f}".format(
                    int(float(correct_count * 100) / model_cap) / 100.0 * H
                )
                + " bits/bit"
            )

            if report_cmat:
                max_cmat_entry_len = len(str(int(np.max(mtrx))))
                mtrx = np.concatenate((labels, mtrx.astype("str")), axis=1).astype(
                    "str"
                )
                max_pred_len = (
                    (mtrx.shape[1] - 1) * max_cmat_entry_len + n_classes * 2 - 1
                )
                print("\nConfusion Matrix:\n")
                print(
                    cmat_template_1.format(
                        pad("Actual", max_class_name_len, False), "Predicted"
                    )
                )
                print(
                    cmat_template_1.format(
                        "-" * max_class_name_len, "-" * max(max_pred_len, 9)
                    )
                )
                for row in mtrx:
                    print(
                        cmat_template_2.format(
                            *[
                                pad(
                                    field,
                                    max_class_name_len
                                    if i == 0
                                    else max_cmat_entry_len,
                                    False,
                                )
                                for i, field in enumerate(row)
                            ]
                        )
                    )

            print("\nAccuracy by Class:\n")
            print(
                acc_by_class_template_1.format(
                    *[
                        pad(header_field, length, False)
                        for i, (header_field, length) in enumerate(
                            zip(acc_by_class_header_fields, acc_by_class_lengths)
                        )
                    ]
                )
            )
            print(
                acc_by_class_template_1.format(
                    *["-" * length for length in acc_by_class_lengths]
                )
            )

            pct_format_string = "{:8.2%}"  # width = 8, decimals = 2
            for raw_class in mapping.keys():
                class_stats = stats[int(mapping[raw_class.strip()])]
                TP, FP, TN, FN = (
                    class_stats.get("TP", None),
                    class_stats.get("FP", None),
                    class_stats.get("TN", None),
                    class_stats.get("FN", None),
                )
                TPR = (
                    pct_format_string.format(class_stats["TPR"])
                    if class_stats["TPR"] is not None
                    else "N/A"
                )
                TNR = (
                    pct_format_string.format(class_stats["TNR"])
                    if class_stats["TNR"] is not None
                    else "N/A"
                )
                PPV = (
                    pct_format_string.format(class_stats["PPV"])
                    if class_stats["PPV"] is not None
                    else "N/A"
                )
                NPV = (
                    pct_format_string.format(class_stats["NPV"])
                    if class_stats["NPV"] is not None
                    else "N/A"
                )
                F1 = (
                    pct_format_string.format(class_stats["F1"])
                    if class_stats["F1"] is not None
                    else "N/A"
                )
                TS = (
                    pct_format_string.format(class_stats["TS"])
                    if class_stats["TS"] is not None
                    else "N/A"
                )
                line_fields = [raw_class, TP, FP, TN, FN, TPR, TNR, PPV, NPV, F1, TS]
                print(
                    acc_by_class_template_1.format(
                        *[
                            pad(field, length, False)
                            for i, (field, length) in enumerate(
                                zip(line_fields, acc_by_class_lengths)
                            )
                        ]
                    )
                )


if __name__ == "__main__":
    try:
        __main()
    except PredictorError as e:
        print(e, file=sys.stderr)
        sys.exit(e.code)
    except Exception as e:
        print(
            f"An unknown exception of type {type(e).__name__} occurred.",
            file=sys.stderr,
        )
        sys.exit(-1)
